method: OVANet
dataset:
  name: Office31
  source_domain: amazon
  target_domain: dslr
  n_share: 10 # number of classes to be shared
  n_source_private: 10 # number of classes in source private domain
  n_total: 31 # number of classes in total
dataloader:
  class_balance: true
  num_workers: 8
  batch_size: 36
print_interval: 100
test_interval: 500
max_step: 10000
# training parameters
lr_g: 0.001
lr_c: 0.01
sgd_momentum: 0.9
weight_decay: 0.0005
# weight between loss
lambda_: 0.1









#data:
#  dataset:
#    name: office # choices are ['office', 'officehome', 'caltech-imagenet', 'visda2017']
#    n_share: 10 # number of classes to be shared
#    n_source_private: 0 # number of classes in source private domain
#    n_total: 31 # number of classes in total
#  dataloader:
#    class_balance: true #
#    data_workers: 3 # how many workers to use for train dataloaders
#    batch_size: 36 # batch_size for source domain and target domain respectively
#model:
#  base_model: resnet50
#  temp: 0.05
#train:
#  min_step: 10000 # minimum steps to run. run epochs until it exceeds the minStep
#  lr: 0.01 # learning rate for new layers. learning rate for finetune is 1/10 of lr
#  multi: 0.1
#  weight_decay: 0.0005
#  sgd_momentum: 0.9
#  momentum: 0.0
#  eta: 0.05
#  log_interval: 100
#  thr: 1.15
#  margin: 0.5
#test:
#  test_interval: 500
#  test_only: False # test a given model and exit
#  resume_file: '' # model to test
#  test_feat: False
#misc:
#  gpus: 1 # how many GPUs to be used, 0 indicates CPU only

#log:
#  root_dir: log # the log directory (log directory will be {root_dir}/{method}/time/)
#  log_interval: 10 # steps to log scalars